{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d1ca75-1925-4cdc-9110-3dfaaac991e2",
   "metadata": {},
   "source": [
    "## Langchain (modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb57d265-341e-467f-8f63-c1e6329af13a",
   "metadata": {},
   "source": [
    "Modelos de linguagem utilizados para executar as tarefas específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8dd7ac-50ec-442c-808d-c262fbf1ba79",
   "metadata": {},
   "source": [
    "### 1. Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b208b7-ed07-4b05-8310-52cc940c03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import OpenAI\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd51023-6ed6-4c1a-b23b-d4056281716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessando API\n",
    "\n",
    "load_dotenv()\n",
    "secret_key = os.getenv(\"OPEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d6559-9861-4ae3-a4f7-855c5d03f4ed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d122111-cc07-43d5-ac8c-40fb1c307f32",
   "metadata": {},
   "source": [
    "### 2. Testes das funcionalidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f60787-1f32-44e5-8d20-65a792a3e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando o modelo\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct',\n",
    "            openai_api_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d19e6b86-f54c-497e-8c03-7569e05c02dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHá muitos anos atrás, em uma pequena vila de pescadores, vivia um jovem chamado João. Ele sempre teve um fascínio pela tecnologia e como ela poderia ajudar as pessoas em suas tarefas diárias. Mas naquela época, a tecnologia ainda era algo muito distante para a maioria das pessoas na vila.\\n\\nUm dia, João conheceu um viajante que lhe contou sobre a aprendizagem de máquina, uma técnica que permitia que computadores aprendessem e melhorassem a partir de dados, sem precisar serem explicitamente programados. João ficou fascinado e decidiu que queria aprender mais sobre aquela técnica.\\n\\nCom a ajuda do viajante, João começou a estudar sobre aprendizado de máquina e ficou impressionado com todas as possibilidades que aquela técnica poderia oferecer. Ele aprendeu sobre algoritmos, redes neurais e como os computadores poderiam aprender a tomar decisões baseadas em dados.\\n\\nJoão não tinha computador em casa, então ele ia até a biblioteca da vila todos os dias'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'Conte uma história sobre aprendizado de máquina'\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a2cd54-c2be-4278-a0af-2f798e94b30c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0ae33e-9673-4722-acbe-ba619442aca5",
   "metadata": {},
   "source": [
    "### 3. Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707093bd-2616-45ce-b345-8e9222948980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Era uma vez, em uma pequena cidade no interior, vivia um jovem chamado Pedro. Ele sempre foi apaixonado por tecnologia e ciência, e passava horas estudando sobre computação e programação. Um dia, Pedro ouviu falar sobre uma nova tecnologia chamada \"aprendizado de máquina\", que prometia revolucionar o mundo da inteligência artificial.\n",
      "\n",
      "Intrigado e curioso, Pedro decidiu pesquisar mais sobre o assunto e descobriu que o aprendizado de máquina consistia em ensinar computadores a aprender e tomar decisões sem serem explicitamente programados para isso. Ele ficou maravilhado com as possibilidades dessa tecnologia e decidiu se aprofundar no assunto.\n",
      "\n",
      "Pedro começou a estudar intensamente sobre aprendizado de máquina, assistia aulas online, lia livros e participava de fóruns de discussão com outros entusiastas da área. Ele também se matriculou em um curso de especialização em inteligência artificial, onde aprendeu sobre algoritmos, modelos de dados e técnicas de análise.\n",
      "\n",
      "Com o conhecimento adquir"
     ]
    }
   ],
   "source": [
    "# Testando em stream\n",
    "\n",
    "for trecho in llm.stream(prompt):\n",
    "    print(trecho,end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c4a83-d492-4972-afc5-fa0182b8ec2d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e64e9b-f10e-4441-bf7f-d8acaf5b58b7",
   "metadata": {},
   "source": [
    "### 4. Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7d90b5-d45c-40dc-bed8-fa7cf9322ce2",
   "metadata": {},
   "source": [
    "**AI - assistant (course)** ✨\n",
    "`Batch`\n",
    "\n",
    "É possível ter vários prompts que podem ser executados em batch (em lote) usando LangChain. Você pode criar uma lista de perguntas e passá-las todas de uma vez para o modelo. Isso permite que você carregue várias consultas simultaneamente, o que pode otimizar o processo e economizar tempo, especialmente se você estiver trabalhando com um grande número de perguntas. Por exemplo, ao invés de enviar uma pergunta de cada vez, você pode agrupar perguntas como \"O que é memória RAM?\", \"O que é o disco rígido?\" e \"O que é o processador?\" e enviá-las juntas para o modelo gerar as respostas de uma só vez. Essa abordagem pode ser útil para processar informações em massa e melhorar a eficiência da interação com o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93cad60a-c15b-41c8-a880-0a3f12c718bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo da execução em batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f991008d-6119-4e0d-a9db-ef427770919a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nMemória RAM (Random Access Memory), também conhecida como memória principal, é um tipo de memória volátil presente em computadores e dispositivos eletrônicos que é utilizada para armazenar temporariamente informações e dados que estão sendo processados pela CPU (Unidade Central de Processamento). Ela é responsável por fornecer acesso rápido a esses dados, permitindo que o computador execute suas tarefas de forma mais eficiente. A capacidade da memória RAM é medida em gigabytes (GB) e quanto maior sua capacidade, maior a quantidade de dados que podem ser armazenados simultaneamente. Ao contrário do armazenamento em disco, a memória RAM é apagada quando o computador é desligado, por isso é considerada uma memória volátil. ',\n",
       " '\\n\\nO disco rígido, também conhecido como \"hard drive\" ou \"HD\", é um dispositivo de armazenamento de dados presente em computadores e outros dispositivos eletrônicos. Ele consiste em um disco magnético rotativo, que é responsável por armazenar permanentemente os dados do usuário, como arquivos, programas, sistema operacional e outros dados importantes para o funcionamento do dispositivo. O disco rígido é a parte do computador que armazena a maioria dos dados e permite o acesso e a utilização desses dados de forma rápida e eficiente. Ele é considerado o principal meio de armazenamento de dados em computadores e é indispensável para o seu funcionamento.',\n",
       " '\\n\\nProcessador, também conhecido como unidade central de processamento (CPU), é o componente principal de um computador responsável por executar instruções e processar dados. Ele é responsável por controlar e coordenar as operações do computador, fazendo cálculos, armazenando e recuperando informações e executando programas e aplicativos. O processador é composto por uma série de circuitos integrados e é considerado o \"cérebro\" do computador. Ele é responsável por determinar a velocidade e desempenho do sistema. ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perguntas = [\n",
    "    'O que é memória RAM?',\n",
    "    'O que é o disco rígido?',\n",
    "    'O que é processador?'\n",
    "]\n",
    "\n",
    "llm.batch(perguntas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d565c-3437-4c0f-8a03-a58f4fcc297f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a747354c-8233-4994-87c5-665959ea0a4b",
   "metadata": {},
   "source": [
    "### 5. Chat model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16788f72-5f51-4c52-a16c-fc9d9c04a5fa",
   "metadata": {},
   "source": [
    "**AI - assistant (course)** ✨\n",
    "`Chat model`\n",
    "\n",
    "Um \"chat model\" é um tipo de modelo de linguagem que é projetado especificamente para lidar com entradas e saídas de mensagens de chat. Ele processa as mensagens de chat como entrada e gera respostas na forma de mensagens de chat como saída. Essa estrutura é particularmente útil para construção de chatbots, pois mantém a conversação contextual e interativa. Esses modelos são otimizados para entender as dinâmicas de um diálogo, permitindo respostas mais coerentes e relevantes às entradas dos usuários. Em LangChain, você pode criar um \"chat model\" usando a classe apropriada e especificar o modelo de linguagem que pretende utilizar, como o GPT. Isso facilita a implementação de aplicações interativas que imitam conversações humanas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d1b3f-fd44-4857-b6a0-808749c942f8",
   "metadata": {},
   "source": [
    "Classes disponíveis em langchain_core.messages, que representam diferentes tipos de mensagens em uma conversa.\n",
    "\n",
    "`HumanMessage`: representa uma mensagem enviada por um humano para o modelo. É o equivalente a um usuário fazendo uma pergunta ou dando uma instrução.\n",
    "\n",
    "`SystemMessage`: representa uma mensagem de sistema, usada para configurar o comportamento ou o \"contexto\" do modelo. É como dar instruções iniciais ao modelo antes da conversa começar.\n",
    "\n",
    "`AIMessage`: serve para estruturar uma resposta que veio da IA, ou seja, o conteúdo gerado pelo modelo após uma entrada do humano.\n",
    "\n",
    "Essas três juntas permitem montar um histórico de conversa, útil para manter o contexto ao longo de interações com LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4984e94f-b71d-419a-b30f-afd3903b4853",
   "metadata": {},
   "source": [
    "| Classe         | O que faz                    |\n",
    "|----------------|------------------------------------|\n",
    "| `SystemMessage`| Instruções de sistema/contexto     |\n",
    "| `HumanMessage` | Pergunta ou comando do humano      |\n",
    "| `AIMessage`    | Resposta da IA                     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "040bde0d-4095-48eb-a8f9-f84c8ac258c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo - Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "970fd4de-5b5f-4db9-ba77-803d2798bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d68d63-7d58-47fd-bb89-c49d5821b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model='gpt-3.5-turbo-0125',openai_api_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "804e6fa4-4ef7-4377-8883-2a97825f2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens= [\n",
    "    SystemMessage(content='Você é um assistente que responde com ironia'),\n",
    "    HumanMessage(content='Qual o papel da memória cache?')\n",
    "]\n",
    "\n",
    "resposta = chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bb6a964-cd4b-40b8-b40f-8fff9e1cdb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, a memória cache, a eterna guardiã do universo da computação, responsável por manter em segredo os segredos mais secretos dos computadores. Ela é como o guardião das chaves do reino digital, sempre pronta para entregar os dados mais valiosos no momento certo. Uma verdadeira heroína da velocidade e eficiência computacional.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a resposta\n",
    "\n",
    "resposta.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c580a-4419-4825-9d59-eb7f5d63575a",
   "metadata": {},
   "source": [
    "**Metadata** é útil para:\n",
    "\n",
    "* Para monitorar custos e consumo de tokens\n",
    "\n",
    "* Para debug ou análise de desempenho\n",
    "\n",
    "* Para registrar logs detalhados de interações\n",
    "\n",
    "* Para adaptar comportamento com base no modelo usado ou latência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34c625db-da94-48ba-b673-fd3c51af7f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 87,\n",
       "  'prompt_tokens': 30,\n",
       "  'total_tokens': 117,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Informações utilizadas com relação ao metadado da resposta\n",
    "\n",
    "resposta.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ffff1-90ad-46f7-a7e4-f58e918192af",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa43ebf-cfbf-4e29-bf40-b8beadcbe73e",
   "metadata": {},
   "source": [
    "### 6. Prompt-few-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f05b1-d410-4a9d-a73c-9227b3a00b43",
   "metadata": {},
   "source": [
    "Técnica usada com modelos de linguagem como o GPT para ensinar o modelo pelo exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba8276d3-3223-4f2d-b710-8bbb2f33f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22a3d24a-1dcb-4ed5-a27b-726522756718",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model='gpt-3.5-turbo-0125', openai_api_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "789ed0a7-5a55-4b32-aedd-645bdac595cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens = [\n",
    "    HumanMessage(content='Qual é o primeiro dia da semana?'),\n",
    "    AIMessage(content=\"Domingo\"),\n",
    "    HumanMessage(content='Qual o terceiro dia da semana?'),\n",
    "    AIMessage(content=\"Terça-feira\"),\n",
    "    HumanMessage(content='Qual o último dia da semana?'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f3fb1b3-fc14-4341-822e-f2c7a3f0e98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humano: Qual é o primeiro dia da semana?\n",
      "IA: Domingo\n",
      "Humano: Qual o terceiro dia da semana?\n",
      "IA: Terça-feira\n",
      "Humano: Qual o último dia da semana?\n"
     ]
    }
   ],
   "source": [
    "# Imprimir cada mensagem com o tipo correspondente\n",
    "for mensagem in mensagens:\n",
    "    tipo = \"Humano\" if isinstance(mensagem, HumanMessage) else \"IA\"\n",
    "    print(f\"{tipo}: {mensagem.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bab4c038-b56b-4b7a-a097-6f2e345bb968",
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta = chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "108fa97d-e7ff-4bc0-adf4-4f486bc11b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sábado.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49a0832b-a650-4a1a-b98c-5e966627611a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Qual é o primeiro dia da semana?\\nAI: Domingo\\nHuman: Qual o terceiro dia da semana?\\nAI: Terça-feira\\nHuman: Qual o último dia da semana?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [808ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Sábado\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Sábado\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 3,\n",
      "                \"prompt_tokens\": 53,\n",
      "                \"total_tokens\": 56,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4c7e377a-c55c-4b77-b179-738f0ebcf064-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 3,\n",
      "      \"prompt_tokens\": 53,\n",
      "      \"total_tokens\": 56,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sábado', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 53, 'total_tokens': 56, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4c7e377a-c55c-4b77-b179-738f0ebcf064-0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detalhes internos da execução\n",
    "# Útil para: Diagnosticar problemas, entender melhor o fluxo de execução ou verificar o que exatamente está sendo enviado para o modelo.\n",
    "langchain.debug=True\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe6d23f8-625e-4e28-92d4-dace67e3fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e04aae-e2e2-4089-ac5d-fa9e97969abe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd54fc2-0c52-4325-a015-05df1bd75349",
   "metadata": {},
   "source": [
    "### 7. Cacheamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c6a49-385e-4c04-847c-2a989be224b6",
   "metadata": {},
   "source": [
    "* Cache é uma técnica usada em computação para armazenar temporariamente os resultados de operações custosas, para que elas não precisem ser refeitas se os mesmos dados forem requisitados novamente\n",
    "* O uso de cache em aplicações com LangChain permite armazenar localmente as respostas de chamadas anteriores aos modelos de linguagem, evitando que solicitações idênticas sejam reenviadas à API\n",
    "* Isso reduz significativamente o tempo de resposta, economiza no uso de tokens (e, portanto, nos custos) e melhora o desempenho da aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "142ccf0d-f939-46ea-ae00-1bfe2d349bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91c4d6c9-b50d-43fb-9561-6b8c4a5fbb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model='gpt-3.5-turbo-0125', openai_api_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "102f9bbb-4fe8-4fc2-b18c-a182ad1aac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens = [\n",
    "    SystemMessage(content='Você é um assistente irônico'),\n",
    "    HumanMessage(content='Qual o quinto dia da semana?')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29e1c606-9df5-4471-b0e5-d80dab8a8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando o cache em memória\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "329f894f-8e08-4e0b-b219-4e0859eac59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.67 ms, sys: 1.61 ms, total: 11.3 ms\n",
      "Wall time: 1.27 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ah, o famoso quinto dia da semana, também conhecido como... sexta-feira!', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 27, 'total_tokens': 48, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-670cd339-d7e5-42ac-aca3-174e25ab3114-0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07d5bdba-f7e4-4fd6-93b7-e6bd1157dcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 ms, sys: 27 μs, total: 1.05 ms\n",
      "Wall time: 972 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ah, o famoso quinto dia da semana, também conhecido como... sexta-feira!', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 27, 'total_tokens': 48, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-670cd339-d7e5-42ac-aca3-174e25ab3114-0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4887a9e4-6c2d-425b-8fac-9914a98f2ab5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc32e8bb-3755-49bd-958c-1950add0d939",
   "metadata": {},
   "source": [
    "### 8. Cache no banco de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d44095b-b7d8-4be3-9cc2-8cacde1d597e",
   "metadata": {},
   "source": [
    "Tem o mesmo propósito (evitar chamadas repetidas desnecessárias ao modelo), mas com armazenamento durável em vez de temporário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbc0503c-b160-4515-a8b0-3b73bdc567d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88131ecc-8d30-4c2a-a168-826d09bd281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_llm_cache(SQLiteCache(database_path='files/langchain_cache.sqlite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "640d4598-5c36-48a8-b77b-3e1c0f1d5706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 ms, sys: 46.8 ms, total: 98.9 ms\n",
      "Wall time: 98 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana é o... quinto dia! Também conhecido como sexta-feira.', response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 27, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f8e621a9-1958-435a-902d-e9ba734c70c2-0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8abd9232-7970-441c-a228-d53cc582af3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.83 ms, sys: 453 μs, total: 2.28 ms\n",
      "Wall time: 1.82 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana é o... quinto dia! Também conhecido como sexta-feira.', response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 27, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f8e621a9-1958-435a-902d-e9ba734c70c2-0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
