{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1e8dd4-2f03-4036-9a95-557620dc3522",
   "metadata": {},
   "source": [
    "# Open IA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6832f5-2796-47d6-a5a7-7332f7f10d09",
   "metadata": {},
   "source": [
    "Primeiras aplicações utilizando a biblioteca `OpenIA`.\n",
    "\n",
    "Objetivo:\n",
    "* Utilizar a API da Open IA para fazer perguntas e gerar respostas por meio de um bot\n",
    "* Documentar o processo de geração de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f95fc0-a2b1-47f2-9497-5008e076d9aa",
   "metadata": {},
   "source": [
    "# Configurações iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c1cbaa-2be7-4a1f-a721-c97dc411c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2de5e2-f193-496e-a41e-f0d03e3fb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessando API\n",
    "\n",
    "load_dotenv()\n",
    "secret_key = os.getenv(\"OPEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f6fa886-5d5b-4e28-a1b6-3dcfe4569196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando \n",
    "\n",
    "client = openai.Client(api_key=secret_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc556ab-9662-4b88-aa4c-a8c3c2f0fdec",
   "metadata": {},
   "source": [
    "## Prompt / message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99265356-0f12-44a7-9238-c986199f3d94",
   "metadata": {},
   "source": [
    "**Parâmetro _role_**: define quem está enviando a mensagem\n",
    "\n",
    "Há algumas opções. Pode conter: \"user\", \"assistant\", ou \"system\":\n",
    "\n",
    "- `user` → Mensagem do usuário. Representa a entrada do usuário (você, a pessoa que está fazendo a pergunta).\n",
    "\n",
    "- `assistant` → Resposta da IA (bot que responderá a pergunta) / gerada pelo modelo. OBS: Deve ser usada para armazenar as respostas da IA quando mantemos um histórico da conversa.\n",
    "\n",
    "\n",
    "- `system` → Instruções para a IA. Define regras ou diretrizes para o modelo. Isso ajuda a configurar o comportamento da IA antes de ela responder ao usuário.É útil para definir estilo, tom de resposta ou contexto específico.\n",
    "\n",
    "\n",
    "**Parâmetro _content_**: o conteúdo da mensagem enviada (texto enviado pelo usuário)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677fd7a6-2ef7-4001-80a2-227616fed7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Defina um morango em 5 palavras\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8052097a-7651-4f63-a039-cdff50627a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [{\"role\": \"user\", \"content\":prompt}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b682e1bd-443c-499e-9b22-0be061a39e1c",
   "metadata": {},
   "source": [
    "## Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa54789d-8990-4eb0-931c-b04115e81836",
   "metadata": {},
   "source": [
    "_Completion_: Resposta gerada pelo modelo.\n",
    "\n",
    "Parâmetros:\n",
    "- `messages` → mensagem criada e definida anteriormente (seção acima)\n",
    "- `model` → modelo do GPT (exemplos: gpt-3.5-turbo-0125, gpt-4, gpt-4-turbo)\n",
    "- `max_tokens` → define o máximo de tokens (unidades de palavras/frases) que a resposta pode ter\n",
    "- `temperature` → controla o grau de aleatoriedade da resposta (varia de 0 a 1). 0: respostas deterministicas e precisas. 1: respostas criativas e variadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6b7515f-9e8e-457d-94fb-987267dab0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    messages=message,\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    max_tokens=1000,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f55e48-0baf-4df2-85d1-abde607e542d",
   "metadata": {},
   "source": [
    "A variável vai retornar a resposta do modelo. O que temos de interesse está em `message=ChatCompletionMessage(content=)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2162804-71e3-4422-abb5-ee62037d1a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BHGp22Sx46nzqlp1s0yL1ZxnY1k0Z', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Fruta vermelha, doce e suculenta.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743455940, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=14, prompt_tokens=19, total_tokens=33, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "747dddff-3ef3-45dc-b39a-382298385c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fruta vermelha, doce e suculenta.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolando a parte de interesse\n",
    "\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce28a3e6-13f4-4ff7-aa55-2aed15aba75f",
   "metadata": {},
   "source": [
    "- Adicionando mais coisas na lista de perguntas\n",
    "- Trocar agora o role para o assistant (que no nosso caso, é o bot que responde a pergunta)\n",
    "- Sempre que o role for 'assistant' = bot\n",
    "- Sempre que o role for 'user' = pergunta de entrada do usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8107895a-edef-4784-b83b-fe567d801a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armazenando resposta do bot\n",
    "\n",
    "message.append({'role':'assistant','content':completion.choices[0].message.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38a4a33d-7853-4b7f-870b-3c4b6f87340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserindo nova pergunta\n",
    "\n",
    "message.append({'role':'user','content':'e tem mais alguma cor nessa fruta?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a0a7ad-9dcf-45fb-8e6b-e616632bd013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta gerada pelo modelo\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    messages=message,\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    max_tokens=1000,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d01f0482-955b-4525-aa0a-bf72bd4016a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sim, o morango também pode ter tons de rosa e até mesmo branco.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolando resposta do modelo\n",
    "\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a01b1bf7-38d7-48d9-9da0-7153c7e75442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armazenando a resposta do bot\n",
    "\n",
    "message.append({'role':'assistant', 'content':completion.choices[0].message.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2050f769-5fa0-448d-9e1d-057793a89dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '\\nDefina um morango em 5 palavras\\n'},\n",
       " {'role': 'assistant', 'content': 'Fruta vermelha, doce e suculenta.'},\n",
       " {'role': 'user', 'content': 'e tem mais alguma cor nessa fruta?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Sim, o morango também pode ter tons de rosa e até mesmo branco.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibindo o histórico\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab245ab5-8e46-4527-8814-feecaf88729e",
   "metadata": {},
   "source": [
    "## Automação do script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c323fd3-228d-4326-9ae4-be53eec23e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma função com as utilizações acima\n",
    "\n",
    "def geracao_texto(mensagens,model='gpt-3.5-turbo-0125',max_tokens=1000,temperature=0):\n",
    "    resposta = client.chat.completions.create(\n",
    "        messages=mensagens,\n",
    "        model=model,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    mensagens.append({'role':'assistant','content': resposta.choices[0].message.content})\n",
    "    return mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f2a2cae-d8de-40b9-a690-0b96aaa02ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg1 = [{'role':'user','content':'Defina o que é API em 5 palavras'}]\n",
    "teste = geracao_texto(msg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c09cbb1-f462-4f15-bb97-d4babee066d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Defina o que é API em 5 palavras'},\n",
       " {'role': 'assistant', 'content': 'Interface de programação de aplicativos.'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940beabe-f64c-4d15-893d-d9d6dec353ce",
   "metadata": {},
   "source": [
    "### Mais parâmetros interessantes\n",
    "\n",
    "`Store` e `Stream`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e2c3d-0d51-439c-a669-a612b1e55be9",
   "metadata": {},
   "source": [
    "`Store`: parâmetro que controla se a resposta gerada pela API deve ser armazenada (ou não) no sistema. Isso pode ser útil, por exemplo, para permitir que você armazene as respostas para análises posteriores ou para o histórico de um chat.\n",
    "\n",
    "* Usar store=True para armazenar a resposta gerada, algo que pode ser útil em situações onde se  quer manter o histórico de interações\n",
    "* Na API da OpenAI, o valor padrão para o parâmetro store é True. Isso significa que, por padrão, as respostas geradas pela API serão armazenadas automaticamente.\n",
    "* Se não precisar armazenar a resposta para análise futura, pode-se definir store=False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ebef8-9a96-47d7-84b6-d69dd1e956ea",
   "metadata": {},
   "source": [
    "`Stream`: parâmetro que permite que você receba a resposta de forma parcial e contínua enquanto a geração ainda está acontecendo. Em vez de esperar até que a resposta completa seja gerada, com o streaming, a resposta começa a ser enviada imediatamente, à medida que o modelo gera cada parte do texto.\n",
    "\n",
    "* Usar o stream=True se quiser visualizar a resposta sendo gerada em tempo real, por exemplo, em um chatbot ao vivo ou quando você precisa exibir a resposta enquanto ela ainda está sendo processada\n",
    "* Isso cria um efeito de \"digitação\" do modelo, onde o texto aparece dinamicamente enquanto é gerado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02efa4a-0ab1-443a-bf17-c1341f8d8992",
   "metadata": {},
   "source": [
    "### Utilizando Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fa6ffe6-c64a-4c37-8f04-f93caaea7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [{'role':'user','content':'Diga quais as cores da bandeira do Brasil e o que cada uma representa'}]\n",
    "completion = client.chat.completions.create(\n",
    "    messages=message,\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    stream=True # Testando o stream aqui\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "191abdaa-a0a1-4e69-9e8e-76fef20016c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.Stream at 0x7d6125f35ca0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion # gera um objeto stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f19fc97-34d5-4ea7-96b5-26ea1798e639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A bandeira do Brasil é composta por quatro cores: verde, amarelo, azul e branco.\n",
      "\n",
      "- Verde: representa as matas e florestas do país, simbolizando a esperança e a riqueza natural.\n",
      "- Amarelo: simboliza as riquezas minerais do Brasil, como o ouro, e representa a riqueza do país.\n",
      "- Azul: representa o céu e os rios do Brasil, simbolizando a união entre o céu e a água.\n",
      "- Branco: simboliza a paz e a pureza, representando a harmonia entre os povos do Brasil."
     ]
    }
   ],
   "source": [
    "# OBS: só funciona com for\n",
    "\n",
    "for completion_stream in completion:\n",
    "    text = completion_stream.choices[0].delta.content\n",
    "    if text:\n",
    "        print(text, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
